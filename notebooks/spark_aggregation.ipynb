{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook – Spark Aggregation (Conceptual)\n",
    "\n",
    "## Ziel\n",
    "Dieses Notebook ist vorgesehen, um Apache Spark für die stündliche\n",
    "Aggregation großer Reddit-Datensätze einzusetzen und damit\n",
    "skalierbare Datenverarbeitung zu demonstrieren.\n",
    "\n",
    "## Kontext im Projekt\n",
    "Dieses Notebook repräsentiert konzeptionell die Big-Data-Processing-Schicht\n",
    "der Pipeline zwischen Rohdatenspeicherung und Visualisierung.\n",
    "\n",
    "## Geplanter Input\n",
    "- `data/raw/reddit_raw.parquet`\n",
    "\n",
    "## Geplanter Output\n",
    "- `data/processed/reddit_hourly.parquet`\n",
    "- Aggregation: Anzahl Posts pro Stunde und Subreddit\n",
    "\n",
    "## Annahmen & Einschränkungen\n",
    "- Aktuell keine Sentiment-Features enthalten\n",
    "- Ausführung zunächst lokal (Single-Node Spark)\n",
    "\n",
    "## TODO / Next Steps\n",
    "- Implementierung der Spark-Session\n",
    "- Definition der Aggregationslogik\n",
    "- Erweiterung um Sentiment-Metriken\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
